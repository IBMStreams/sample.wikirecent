{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "\n",
        "# 0 : Real time analysis of wikipedia updates - \n",
        "This notebook is the first in a series showing the progression of a developer or data professional with developer skills moving from data exploration, modular application building to delivering consumable visualizations on Machine learnt analysis.\n",
        "\n",
        "- Data exploration in pure python\n",
        "- Data aggregation and filtering\n",
        "- Data windowing\n",
        "- Data data extraction.\n",
        "- Image analyisis\n",
        "\n",
        "We are exploring a publicly available and accessible streaming data source from Mediawiki.org. MediaWiki is a free and open source software wiki package written in PHP, originally for use on Wikipedia. The website maintained to promote this open source offering offers an accessible feed of changes to all of the pages and assets that make it up. People editing Media wiki pages are around the world, working in different languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Streaming data exploration\n",
        "\n",
        "Data science projects commonly start with a data set with defined characteristcs. A data professional will explore the data. Assess it for completeness, quality and relevance to the project purpose.\n",
        "\n",
        "For streaming data, the process is similar even though the actual data elements are constantly changing. This notebook show those first exploration steps to allow a data professional to understand the data they are presented with for analysis.\n",
        "\n",
        "The specification of the mediawiki feed can be found here. https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams\n",
        "\n",
        "The data is streamed using the Server-Sent Events (SSE) protocol. This is similar in some respects to Websockets, however SSE is one-way only and uses HTTP as the transport. \n",
        "The feed itself is available here. https://stream.wikimedia.org/v2/stream/recentchange\n",
        "\n",
        "In this exploration phase we are using pure Python in a Jupyter notebook for this data exploration. In later steps the code we develop here will become the seed for our Streams application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SSEClient in /Users/siegenth/anaconda3/lib/python3.5/site-packages (0.0.19)\r\nRequirement already satisfied: six in /Users/siegenth/anaconda3/lib/python3.5/site-packages (from SSEClient) (1.11.0)\r\nRequirement already satisfied: requests\u003e\u003d2.0.0 in /Users/siegenth/anaconda3/lib/python3.5/site-packages (from SSEClient) (2.5.1)\r\n",
            "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\r\nYou should consider upgrading via the \u0027pip install --upgrade pip\u0027 command.\u001b[0m\r\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": [
        "!pip install SSEClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, clear_output\n",
        "from sseclient import SSEClient as EventSource\n",
        "import time\n",
        "import json\n",
        "from statistics import mean\n",
        "from collections import deque\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Define functions and helpers to use for our exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"This is the core function for tapping into the feed\"\"\"\n",
        "def get_events(url\u003d\"https://stream.wikimedia.org/v2/stream/recentchange\"):\n",
        "    \"\"\"fetch recent changes from wikievents site using SSE\"\"\"\n",
        "    for change in EventSource(url):\n",
        "        \"\"\"for each change record in this fetch\"\"\"\n",
        "        if len(change.data):\n",
        "            \"\"\"if the change contains any data\"\"\"\n",
        "            yield json.loads(change.data)\n",
        "            \"\"\"Return it as a json object\"\"\"\n",
        "                 \n",
        "def catchInterrupt(func):\n",
        "    \"\"\"decorator : when interupt occurs the display is lost if you don\u0027t catch it\n",
        "       TODO * \u003cview\u003e.stop_data_fetch()  # stop\n",
        "\n",
        "    .\"\"\"\n",
        "    def catch_interrupt(*args, **kwargs):\n",
        "        try: \n",
        "            func(*args, **kwargs)\n",
        "        except (KeyboardInterrupt): pass\n",
        "    return catch_interrupt\n",
        "\n",
        "@catchInterrupt\n",
        "def sample_events(wait_between\u003d5, interations\u003d1):\n",
        "    \"\"\"fetch events from Wikipedia, display and repeat. \n",
        "    ..note:: \n",
        "        Helper to look at the raw feed, with this you can see all the fields retrned\n",
        "    Args: \n",
        "        - wait_between : seconds to wait between samples\n",
        "        - interations \u003d number of interations, \u003c 0 infinite\n",
        "    \"\"\"\n",
        "    for evt in get_events():\n",
        "        if interations \u003d\u003d 0: break\n",
        "        interations -\u003d 1\n",
        "        print(json.dumps(evt, indent\u003d1, sort_keys\u003dTrue))\n",
        "        time.sleep(wait_between)\n",
        "        clear_output(wait\u003dTrue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The cell below displays a subset of the fields that are available. Invoking \n",
        "the sample_events() will return the full complement of fields. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "@catchInterrupt\n",
        "def table_events(chunk_size\u003d10, column_keys\u003d[], interations\u003d10):\n",
        "    \"\"\"Display selected columns in in table, in chunk_size.\n",
        "    Args::\n",
        "        - column_keys : columns to display\n",
        "        - chunk_size : number of columns to show at a time.\n",
        "        - interations : number of times to loop, \u003c\u003d0 is infinite\n",
        "    \"\"\"\n",
        "    while interations !\u003d 0:\n",
        "        lst \u003d []\n",
        "        interations -\u003d 1\n",
        "        for evt in get_events():\n",
        "            lst.append(evt)\n",
        "            if len(lst) \u003e chunk_size: break\n",
        "        dList \u003d pd.DataFrame(lst)\n",
        "        print(dList[column_keys])\n",
        "        clear_output(wait\u003dTrue)\n",
        "        \n",
        "table_events(column_keys\u003d[\"type\", \"bot\", \"user\", \"wiki\", \"title\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Focus on type\n",
        "\n",
        "The events are characterized with the possible values of: new, edit, catagorize and log. \n",
        "We\u0027ll drill down into event types arriving, showing the counts for a chunk of 20 events and averaging over\n",
        "5 chunks. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "# Aggregate collections of rows\n",
        "\n",
        "class chunking_average:\n",
        "    \"\"\"Aggregate field values\"\"\"\n",
        "    def __init__(self, init_base, mean_elements\u003d20):\n",
        "        self.deques \u003d {key:deque([0],maxlen\u003dmean_elements) for key in init_base.keys()}\n",
        "\n",
        "    def aggregate(self, chunk):\n",
        "        for key in self.deques.keys():\n",
        "            if self.deques[key] and chunk[key]: self.deques[key].append(chunk[key])\n",
        "        return {key:mean(self.deques[key]) for key in self.deques.keys()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "# tally the the types\n",
        "#from collections import Counter\n",
        "\n",
        "@catchInterrupt\n",
        "def graph_type(events_window\u003d20, average_windows\u003d5, interations\u003d5):\n",
        "    \"\"\"Display graph of page types arriving, windows and average windows worth. \n",
        "    \n",
        "    Args:\n",
        "        - events_window : number of updates within a window.\n",
        "        - average_windows : number of windows average\n",
        "    \n",
        "    \"\"\"\n",
        "    interations +\u003d average_windows\n",
        "    cnt \u003d dict({\"new\":0, \"edit\":0, \"categorize\":0,\"log\":0})\n",
        "    run_avg \u003d chunking_average(cnt)\n",
        "    try: \n",
        "        while interations !\u003d 0:\n",
        "            interations -\u003d 1\n",
        "            for evt in get_events():\n",
        "                if evt[\u0027type\u0027] in cnt:\n",
        "                    cnt[evt[\u0027type\u0027]] +\u003d 1\n",
        "                    if sum(cnt.values()) \u003e events_window: break\n",
        "            avg \u003d run_avg.aggregate(cnt)\n",
        "            if average_windows \u003c\u003d 0:\n",
        "                clear_output(wait\u003dTrue)\n",
        "                nam_list \u003d [key for key in cnt.keys()]\n",
        "                evt_list \u003d [cnt[key] for key in nam_list]\n",
        "                avg_list \u003d [avg[key] for key in nam_list]\n",
        "                df \u003d pd.DataFrame({\u0027count\u0027: evt_list, \u0027running avg\u0027: avg_list}, index\u003dnam_list)\n",
        "                df.plot.bar(rot\u003d0)\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"Elements to stage ...{} \".format( average_windows))\n",
        "                average_windows -\u003d 1\n",
        "            cnt \u003d {key:0 for key in cnt}\n",
        "    except (KeyboardInterrupt): pass\n",
        "graph_type()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Notebook wrapup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "With this notebook we\u0027ve accessed live wikipedia data, done redumentary calculations and graphed it.\n",
        "Since all the components are in a notebook, data is only collected while the notebook is open which \n",
        "provides only limited insights what is happening. \n",
        "\n",
        "Collecting the data continiously is the next phase. In addition to the collecting we\u0027ll do some intial processing \n",
        "of the live data make it more consumable. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}