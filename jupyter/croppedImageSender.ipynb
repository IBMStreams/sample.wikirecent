{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# croppedImageSender - docs and install\n",
    "\n",
    "Interactive cropping tool to define region of interest on a video frame and \n",
    "send the video frames to the Streams application.\n",
    "\n",
    "This is the cropping tool...\n",
    "- https://openbits.app/posts/python-interactive-cropping/\n",
    "\n",
    "You need to install it:\n",
    "```\n",
    "pip install interactivecrop\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The orignal test code\n",
    "# crop(sample_images, sample_names, optimize=True, continuous_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify video that will be cropped and analyized. \n",
    "**StaticVideo** should point to the video that is to analyized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "StaticVideo = '/Users/siegenth/Data/airportGate.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import all the support components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactivecrop.interactivecrop import main as crop\n",
    "from interactivecrop.samples import sample_images, sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Send video, frame-by-frame to Kafka interface\n",
    "- Frame is encoded into ascii so no one gets upset with the data.\n",
    "- Frame will be decomposed into chunks of 'CHUNK_SIZE'. When debugging found Kafka would not send message if it went over threshold.\n",
    "- Receiving test notebook VideoRcvKafka\n",
    "- The Steams application VideoRcvKafka recieves the encode image and scores it with Model.\n",
    "\n",
    "\"\"\"\n",
    "import kafka\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import base64\n",
    "import ssl\n",
    "import time\n",
    "import datetime\n",
    "import io\n",
    "from PIL import Image\n",
    "import logging\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "if '../juypter' not in sys.path:\n",
    "    sys.path.insert(0, '../juypter')\n",
    "import credential\n",
    "import streams_aid as aid\n",
    "\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "# img_encoded = str(base64.b64encode(response.content).decode(\"utf-8\"))\n",
    "# img_encoded = str(base64.b64encode(img).decode('utf-8'))\n",
    "\n",
    "\n",
    "def bts_to_img(bts):\n",
    "    buff = np.fromstring(bts, np.uint8)\n",
    "    buff = buff.reshape(1, -1)\n",
    "    img = cv2.imdecode(buff, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def encode_img(img):\n",
    "    \"\"\"must be easier way\"\"\"\n",
    "    with io.BytesIO() as output:\n",
    "        img.save(output, format=\"JPEG\")\n",
    "        contents = output.getvalue()\n",
    "    return base64.b64encode(contents).decode('ascii')\n",
    "\n",
    "\n",
    "def decode_img(bin64):\n",
    "    \"\"\"must be easier way\"\"\"\n",
    "    img = Image.open(io.BytesIO(base64.b64decode(bin64)))\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and image from video and set region of interest. \n",
    "\n",
    "\n",
    "### collect one frame from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 1 frames at the 30 second mark.\n"
     ]
    }
   ],
   "source": [
    "def collect_frames(video_url, frame_count=1, frame_modulo=24, debug=False):\n",
    "    \"\"\"collect a set of frames from the video to work out the cropping region. \n",
    "    Notes:\n",
    "        - pull out the frames based upon the modulo and frame_count\n",
    "        - the correct way, find frames that hav signficant difference between each\n",
    "        - now \n",
    "    \n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    \"\"\"get the crop region for a video.\n",
    "    []  pull up some frames...\n",
    "    [x] - send frames to cropper\n",
    "    [x] - get cropper regionquick\n",
    "\n",
    "    :param kafka_prod: the handle to sent out messages on kafka\n",
    "    :param frame_modulo: send every x frames\n",
    "    :param send_wait: after sending a frame wait time\n",
    "    :param debug: decode image and write out to verify\n",
    "    :return: None\n",
    "\n",
    "    \"\"\"\n",
    "    frame_num = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(video_url)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        frame_num += 1\n",
    "        if not(frame_num % frame_modulo):            \n",
    "            if debug:\n",
    "                image_encoded =encode_img(Image.fromarray(frame, 'RGB'))\n",
    "                # debugging - render what we will send.\n",
    "                img_raw = decode_img(image_encoded)\n",
    "                plt.imshow(img_raw)\n",
    "                plt.show()\n",
    "            # break down frame into chunks\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        if frame_count <= len(frames):\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames\n",
    "\n",
    "secs = 30 \n",
    "frames = collect_frames(video_url=StaticVideo,frame_modulo=30*secs,\n",
    "              frame_count=1, debug=False)\n",
    "print(\"Collected {} frames at the {} second mark.\".format(len(frames), secs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the collected frame to define a crop region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SHAPE = None\n",
    "def grabCropShape(image_name, shape):\n",
    "    global SHAPE\n",
    "    SHAPE = shape\n",
    "    print(\"set SHAPE \", image_name, shape, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Press the 'Save Crop Size' button to capture the crop region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae5d5b40a6244ca8100490f67bcb61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Dropdown(description='Img Name:', layout=Layout(grid_area='im_selector', width='100%'), opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3de8c9edfb4bfdac650570cd1f1f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Save Crop Sizes', style=ButtonStyle()), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop(frames, callback=grabCropShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the captured region is what you expected\n",
    "- verify what we collected\n",
    "- **RegionOfInterest** is the cropping specification that will be applied to frame sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-7ebfd0378de4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mimage_encoded\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0mencode_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfromarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'RGB'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mimg_raw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdecode_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_encoded\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Image size : {} crop region : {} \"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_raw\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSHAPE\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m RegionOfInterest = (SHAPE.size[0],\n\u001B[1;32m      5\u001B[0m                         \u001B[0mSHAPE\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "image_encoded =encode_img(Image.fromarray(frames[0], 'RGB'))\n",
    "img_raw = decode_img(image_encoded)\n",
    "print(\"Image size : {} crop region : {} \".format(img_raw.size, SHAPE.size))\n",
    "RegionOfInterest = (SHAPE.size[0],\n",
    "                        SHAPE.size[1],\n",
    "                        SHAPE.size[0]+SHAPE.size[2],\n",
    "                        SHAPE.size[1]+SHAPE.size[3])\n",
    "print(\"regionOfInterest:\",RegionOfInterest)\n",
    "cropped = img_raw.crop(RegionOfInterest)\n",
    "\n",
    "plt.imshow(cropped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Cropped Region...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kafka_producer(credentials):\n",
    "    \"\"\"\n",
    "    Open the connection to the kafka producer\n",
    "    :param credentials:\n",
    "    :return: kafka producer\n",
    "\n",
    "    Request is responsilbe for closing producer.\n",
    "    \"\"\"\n",
    "    prod = None\n",
    "    while prod is None:\n",
    "        try:\n",
    "            prod = kafka.KafkaProducer(bootstrap_servers=credentials[\"kafka_brokers_sasl\"],\n",
    "                                       security_protocol=\"SASL_SSL\",\n",
    "                                       sasl_mechanism=\"PLAIN\",\n",
    "                                       sasl_plain_username=credentials[\"user\"],\n",
    "                                       sasl_plain_password=credentials[\"api_key\"],\n",
    "                                       ssl_cafile=ssl.get_default_verify_paths().cafile)\n",
    "\n",
    "        except kafka.errors.NoBrokersAvailable:\n",
    "            logging.warning(\"No Brokers Available. Retrying ...\")\n",
    "            time.sleep(1)\n",
    "            prod = None\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 100000         # maximum number of bytes to transmit at a time\n",
    "\n",
    "def video_kafka(video_url, regionOfInterest, kafka_prod, kafka_topic='VideoFrame', frame_modulo=24, send_wait=.25, debug=False):\n",
    "    \"\"\"Send video via Kafka\n",
    "\n",
    "    :param video_url: url of video to pull in and send\n",
    "    :param kafka_prod: the handle to sent out messages on kafka\n",
    "    :param frame_modulo: send every x frames\n",
    "    :param send_wait: after sending a frame wait time\n",
    "    :param debug: decode image and write out to verify\n",
    "    :return: None\n",
    "\n",
    "    \"\"\"\n",
    "    frame_num = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(video_url)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        frame_num += 1\n",
    "        if not(frame_num % frame_modulo):\n",
    "            # crop each frame before sending it.\n",
    "            orginal_encoded =encode_img(Image.fromarray(frame, 'RGB'))\n",
    "            img_raw = decode_img(orginal_encoded)\n",
    "            cropped = img_raw.crop(regionOfInterest)\n",
    "            image_encoded = encode_img(cropped)\n",
    "            \n",
    "            \n",
    "            if debug:\n",
    "                # debugging - render what we will send.\n",
    "                img_raw = decode_img(image_encoded)\n",
    "                plt.imshow(img_raw)\n",
    "                plt.show()\n",
    "            # break down frame into chunks\n",
    "            chunks = [image_encoded[i * CHUNK_SIZE:(i + 1) * CHUNK_SIZE] for i in\n",
    "                      range((len(image_encoded) + CHUNK_SIZE - 1) // CHUNK_SIZE)]\n",
    "            # send the chunks.\n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                logging.debug(\"chunking - {}  #chunks :{} idx:{} len(chunk):{}\".format(video_url, len(chunks), idx, len(chunk)))\n",
    "                chunk_content = {'video': video_url,\n",
    "                       'frame': frame_num,\n",
    "                       'chunk_idx':idx,\n",
    "                       'chunk_total':len(chunks),\n",
    "                       'timestamp': datetime.datetime.utcnow().isoformat() + 'Z',\n",
    "                       'data': chunk\n",
    "                }\n",
    "                kafka_prod.send(kafka_topic, value=json.dumps(chunk_content).encode('utf-8'))\n",
    "            ## finish the frame frame\n",
    "            chunk_complete = {'video': video_url,\n",
    "                   'frame': frame_num,\n",
    "                    'chunk_idx': len(chunks),\n",
    "                    'chunk_total': len(chunks),\n",
    "                   'timestamp': datetime.datetime.utcnow().isoformat() + 'Z',\n",
    "                   'data': \"\"\n",
    "                   }\n",
    "            logging.info(\"Transmit frame #{}\".format(chunk_content[\"frame\"]))\n",
    "            kafka_prod.send(kafka_topic, value=json.dumps(chunk_complete).encode('utf-8'))\n",
    "            time.sleep(send_wait)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@aid.catchInterrupt\n",
    "def videoStream(topic=\"VideoFrame\", videoUrl=None, regionOfInterest=None):\n",
    "    creds = json.loads(credential.magsEventStream)\n",
    "    prod = kafka_producer(creds,)\n",
    "    video_kafka(videoUrl, regionOfInterest, prod,  kafka_topic=topic, send_wait=1, frame_modulo=24, debug=False)\n",
    "    prod.close()\n",
    "\n",
    "TOPIC=\"VideoFrame\"    \n",
    "\n",
    "videoStream(topic=TOPIC, videoUrl=StaticVideo, regionOfInterest=RegionOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}