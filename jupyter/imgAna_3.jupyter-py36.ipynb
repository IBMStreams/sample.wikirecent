{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiRecentPhase3\n",
    "\n",
    "[WikiRecentPhase2](./imgAna_2.jupyter-py36.ipynb) illustrated processing Wikipedia events continuously with Streams using the windowing facility to process 'chunks' of events on a time or count basis.\n",
    "Building on the previous notebooks, this extracts images from Wikipedia events and renders them.\n",
    "\n",
    "\n",
    "## Overview - Image Extraction\n",
    "\n",
    "The previous notebooks recieved and filtered events from Wikipedia. This continues the processing of events, determining if the event pertains to an image and extacts the URL using\n",
    "[beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). The image's URL is injected into the stream. This notebook gets the extracted URL via a view and renders it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "# Setup\n",
    "### Add credentials for the IBM Streams service\n",
    "\n",
    "#### ICPD setup\n",
    "\n",
    "With the cell below selected, click the \"Connect to instance\" button in the toolbar to insert the credentials for the service.\n",
    "\n",
    "<a target=\"blank\" href=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/02/connect_icp4d.gif\">See an example</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud setup\n",
    "\n",
    "To use Streams instance running in the cloud setup a [credential.py](setup_credential.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Show me\n",
    "After doing the 'Setup' above you can use Menu 'Cell' | 'Run All' to compose, build, submit and start the rendering of the live Wikidata, go to [Show me now](#showMeNow) for the rendering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sseclient in /Users/siegenth/anaconda3/lib/python3.5/site-packages (0.0.19)\n",
      "Requirement already satisfied: six in /Users/siegenth/anaconda3/lib/python3.5/site-packages (from sseclient) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/siegenth/anaconda3/lib/python3.5/site-packages (from sseclient) (2.5.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: streamsx in /Users/siegenth/.local/lib/python3.5/site-packages (1.12.10)\n",
      "Requirement already satisfied, skipping upgrade: future in /Users/siegenth/.local/lib/python3.5/site-packages (from streamsx) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: dill in /Users/siegenth/anaconda3/lib/python3.5/site-packages (from streamsx) (0.2.7.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/siegenth/anaconda3/lib/python3.5/site-packages (from streamsx) (2.5.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install components\n",
    "!pip install sseclient\n",
    "!pip install --user --upgrade streamsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from statistics import mean\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, HBox, VBox, Layout\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sseclient import SSEClient as EventSource\n",
    "\n",
    "from ipywidgets import Button, HBox, VBox, Layout\n",
    "\n",
    "from  functools import lru_cache\n",
    "import requests\n",
    "\n",
    "from streamsx.topology.topology import *\n",
    "import streamsx.rest as rest\n",
    "from streamsx.topology import context\n",
    "\n",
    "#from streamsx.topology.topology import Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions for Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catchInterrupt(func):\n",
    "    \"\"\"decorator : when interupt occurs the display is lost if you don't catch it\n",
    "       TODO * <view>.stop_data_fetch()  # stop\n",
    "       \n",
    "    \"\"\"\n",
    "    def catch_interrupt(*args, **kwargs):\n",
    "        try: \n",
    "            func(*args, **kwargs)\n",
    "        except (KeyboardInterrupt): pass\n",
    "    return catch_interrupt\n",
    "\n",
    "#\n",
    "# Support for locating/rendering views.\n",
    "def display_view_stop(eventView, period=2):\n",
    "    \"\"\"Wrapper for streamsx.rest_primitives.View.display() to have button. \"\"\"\n",
    "    button =  widgets.Button(description=\"Stop Updating\")\n",
    "    display(button)\n",
    "    eventView.display(period=period) \n",
    "    def on_button_clicked(b):\n",
    "        eventView.stop_data_fetch()\n",
    "        b.description = \"Stopped\"\n",
    "    button.on_click(on_button_clicked)\n",
    "\n",
    "def view_events(views):\n",
    "    \"\"\"\n",
    "    Build interface to display a list of views and \n",
    "    display view when selected from list.\n",
    "     \n",
    "    \"\"\"\n",
    "    view_names = [view.name for view in views]\n",
    "    nameView = dict(zip(view_names, views))    \n",
    "    select = widgets.RadioButtons(\n",
    "        options = view_names,\n",
    "        value = None,\n",
    "        description = 'Select view to display',\n",
    "        disabled = False\n",
    "    )\n",
    "    def on_change(b):\n",
    "        if (b['name'] == 'label'):\n",
    "            clear_output(wait=True)\n",
    "            [view.stop_data_fetch() for view in views ]\n",
    "            display(select)\n",
    "            display_view_stop(nameView[b['new']], period=2)\n",
    "    select.observe(on_change)\n",
    "    display(select)\n",
    "\n",
    "def find_job(instance, job_name=None):\n",
    "    \"\"\"locate job within instance\"\"\"\n",
    "    for job in instance.get_jobs():    \n",
    "        if job.applicationName.split(\"::\")[-1] == job_name:\n",
    "            return job\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def display_views(instance, job_name):\n",
    "    \"Locate/promote and display all views of a job\"\n",
    "    job = find_job(instance, job_name=job_name)\n",
    "    if job is None:\n",
    "        print(\"Failed to locate job\")\n",
    "    else:\n",
    "        views = job.get_views()\n",
    "        view_events(views)\n",
    "\n",
    "def list_jobs(_instance=None, cancel=False):\n",
    "    \"\"\"\n",
    "    Interactive selection of jobs to cancel.\n",
    "    \n",
    "    Prompts with SelectMultiple widget, if thier are no jobs, your presente with a blank list.\n",
    "    \n",
    "    \"\"\"\n",
    "    active_jobs = { \"{}:{}\".format(job.name, job.health):job for job in _instance.get_jobs()}\n",
    "\n",
    "    selectMultiple_jobs = widgets.SelectMultiple(\n",
    "        options=active_jobs.keys(),\n",
    "        value=[],\n",
    "        rows=len(active_jobs),\n",
    "        description = \"Cancel jobs(s)\" if cancel else \"Active job(s):\",\n",
    "        layout=Layout(width='60%')\n",
    "    )\n",
    "    cancel_jobs = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description='Cancel',\n",
    "        disabled=False,\n",
    "        button_style='warning', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Delete selected jobs',\n",
    "        icon=\"stop\"\n",
    "    )\n",
    "    def on_value_change(change):\n",
    "        for job in selectMultiple_jobs.value:\n",
    "            print(\"canceling job:\", job, active_jobs[job].cancel())\n",
    "        cancel_jobs.disabled = True\n",
    "        selectMultiple_jobs.disabled = True\n",
    "\n",
    "    cancel_jobs.observe(on_value_change, names='value')\n",
    "    if cancel:\n",
    "        return HBox([selectMultiple_jobs, cancel_jobs])\n",
    "    else:\n",
    "        return HBox([selectMultiple_jobs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the server :  ICP4D or Cloud instance. \n",
    "Attempt to import if fails the cfg will not be defined we know were using \n",
    "Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside ICP4D\n"
     ]
    }
   ],
   "source": [
    "def get_instance():\n",
    "    \"\"\"Setup to access your Streams instance.\n",
    "\n",
    "    ..note::The notebook is work within Cloud and ICP4D. \n",
    "            Refer to the 'Setup' cells above.              \n",
    "    Returns:\n",
    "        instance : Access to Streams instance, used for submitting and rendering views.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from icpd_core import icpd_util\n",
    "        import urllib3\n",
    "        global cfg\n",
    "        cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "        instance = rest.Instance.of_service(cfg)\n",
    "        print(\"Within ICP4D\")\n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    except ImportError:\n",
    "        cfg = None\n",
    "        print(\"Outside ICP4D\")\n",
    "        import credential  \n",
    "        sc = rest.StreamingAnalyticsConnection(service_name='Streaming3Turbine', \n",
    "                                               vcap_services=credential.vcap_conf)\n",
    "        instance = sc.get_instances()[0]\n",
    "    return instance,cfg\n",
    "\n",
    "instance,cfg = get_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List jobs and cancel....\n",
    "This page will submit a job named 'WikiPhase3'. If it's running you'll want to cancel it before submitting a new version. If it is running, no need to cancel/submit you can just procede to the [Viewing data section](#viewingData)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e648da322057458fb737b4a6ca368e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Active job(s):', layout=Layout(width='60%'), options=(), rows=0, value=()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_jobs(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions that are executed within Streams\n",
    "Details of these functions can be found in previous notebooks of this suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events():\n",
    "    \"\"\"fetch recent changes from wikievents site using SSE\"\"\"\n",
    "    for change in EventSource('https://stream.wikimedia.org/v2/stream/recentchange'):\n",
    "        if len(change.data):\n",
    "            try:\n",
    "                obj = json.loads(change.data)\n",
    "            except json.JSONDecodeError as err:\n",
    "                print(\"JSON l1 error:\", err, \"Invalid JSON:\", change.data)\n",
    "            except json.decoder.JSONDecodeError as err:\n",
    "                print(\"JSON l2 error:\", err, \"Invalid JSON:\", change.data)\n",
    "            else:\n",
    "                yield(obj)\n",
    "\n",
    "\n",
    "class sum_aggregation():\n",
    "    def __init__(self, sum_map={'new_len':'newSum','old_len':'oldSum','delta_len':'deltaSum' }):\n",
    "        \"\"\"\n",
    "        Summation of column(s) over a window's tuples. \n",
    "        Args::\n",
    "            sum_map :  specfify tuple columns to be summed and the result field. \n",
    "            tuples : at run time, list of tuples will flow in. Sum each fields\n",
    "        \"\"\"\n",
    "        self.sum_map = sum_map\n",
    "    def __call__(self, tuples)->dict: \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tuples : list of tuples constituting a window, over all the tuples sum using the sum_map key/value \n",
    "                     to specify the input and result field.\n",
    "        Returns:\n",
    "            dictionary of fields summations over tuples\n",
    "            \n",
    "        \"\"\"\n",
    "        summaries = dict()\n",
    "        for summary_field,result_field in self.sum_map.items():\n",
    "            summation = sum([ele[summary_field] for ele in tuples])\n",
    "            summaries.update({result_field : summation})\n",
    "        return(summaries)\n",
    "\n",
    "import collections\n",
    "class tally_fields(object):\n",
    "    def __init__(self, top_count=3, fields=['user', 'wiki', 'title']):\n",
    "        \"\"\"\n",
    "        Tally fields of a list of tuples.\n",
    "        Args::\n",
    "            fields :  fields of tuples that are to be tallied\n",
    "        \"\"\"\n",
    "        self.fields = fields\n",
    "        self.top_count = top_count\n",
    "    def __call__(self, tuples)->dict:\n",
    "        \"\"\"\n",
    "        Args::\n",
    "            tuples : list of tuples tallying to perform. \n",
    "        return::\n",
    "            dict of tallies\n",
    "        \"\"\"\n",
    "        tallies = dict()\n",
    "        for field in self.fields:\n",
    "            stage = [tuple[field] for tuple in tuples if tuple[field] is not None]\n",
    "            tallies[field] = collections.Counter(stage).most_common(self.top_count)\n",
    "        return tallies\n",
    "\n",
    "import csv\n",
    "class wiki_lang():\n",
    "    \"\"\"\n",
    "    Augment the tuple to include language wiki event.\n",
    "    \n",
    "    Mapping is loaded at build time and utilized at runtime.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fname=\"wikimap.csv\"):\n",
    "        self.wiki_map = dict()\n",
    "        with open(fname, mode='r') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            for row in csv_reader:\n",
    "                self.wiki_map[row['dbname']] = row\n",
    "\n",
    "    def __call__(self, tuple):\n",
    "        \"\"\"using 'wiki' field to look pages code, langauge and native\n",
    "        Args:\n",
    "            tuple: tuple (dict) with a 'wiki' fields\n",
    "        Returns:'\n",
    "            input tuple with  'code', 'language, 'native' fields added to the input tuple.\n",
    "        \"\"\"\n",
    "        if tuple['wiki'] in self.wiki_map:\n",
    "            key = tuple['wiki']\n",
    "            tuple['code'] = self.wiki_map[key]['code']\n",
    "            tuple['language'] = self.wiki_map[key]['in_english']\n",
    "            tuple['native'] = self.wiki_map[key]['name_language']\n",
    "        else:\n",
    "            tuple['code'] = tuple['language'] = tuple['native'] = None\n",
    "        return tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shredding web pages\n",
    "\n",
    "The next phase of the Stream will be to check if the event is associated with an image, if it is extract the \n",
    "image URL. \n",
    "\n",
    "- find possible link to image\n",
    "- build url and use to fetch page, shred,  searching for an image link\n",
    "- shredding can go down mulitple levels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@lru_cache(maxsize=None)\n",
    "def shred_item_image(url):\n",
    "    \"\"\"Shred the item page, seeking image. \n",
    "    \n",
    "    Discover if referencing image by shredding referening url. If it is, dig deeper \n",
    "    and extract the 'src' link. \n",
    "    \n",
    "    Locate the image within the page, locate <a class='image' src=**url** ,..>\n",
    "    \n",
    "    This traverses two files, pulls the thumbnail ref and follows to fullsize.\n",
    "    \n",
    "    Args:\n",
    "        url: item page to analyse\n",
    "    \n",
    "    Returns: \n",
    "        If image found [{name,title,org_url},...]\n",
    "    \n",
    "    .. warning:: this fetches from wikipedia, requesting too frequenty is bad manners. Uses the lru_cache()\n",
    "    so it minimises the requests.\n",
    "    \n",
    "    This can pick up multiple titles, on a page that is extract, dropping to only one. \n",
    "    \"\"\"\n",
    "    img_urls = list()\n",
    "    try:\n",
    "        rThumb = requests.get(url = url)\n",
    "        #print(r.content)\n",
    "        soupThumb = BeautifulSoup(rThumb.content, \"html.parser\")\n",
    "        divThumb = soupThumb.find(\"div\", class_=\"thumb\")\n",
    "        if divThumb is None:\n",
    "            print(\"No thumb found\", url  )\n",
    "            return img_urls\n",
    "        thumbA = divThumb.find(\"a\", class_=\"image\")\n",
    "        thumbHref = thumbA.attrs['href']\n",
    "\n",
    "        rFullImage = requests.get(url=thumbHref)\n",
    "        soupFull = BeautifulSoup(rFullImage.content, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(\"Error request.get, url: {} except:{}\".format(url, str(e)))\n",
    "    else:\n",
    "        divFull = soupFull.find(\"div\", class_=\"fullImageLink\", id=\"file\")\n",
    "        if (divFull is not None):\n",
    "            fullA = divFull.find(\"a\")\n",
    "            img_urls.append({\"title\":soupThumb.title.getText(),\"img\": fullA.attrs['href'],\"org_url\":url})\n",
    "    finally:\n",
    "        return img_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@lru_cache(maxsize=None)\n",
    "def shred_jpg_image(url):\n",
    "    \"\"\"Shed the jpg page, seeking image, the reference begins with 'Fred:' and \n",
    "    ends with '.jpg'.\n",
    "    \n",
    "    Discover if referencing image by shredding referening url. If it is, dig deeper \n",
    "    and extract the 'src' link. \n",
    "    \n",
    "    Locate the image within the page, \n",
    "            locate : <div class='fullImageLinks'..>\n",
    "                         <a href=\"..url to image\" ...>.</a>\n",
    "                         :\n",
    "                     </div>  \n",
    "    Args:\n",
    "        url: item page to analyse\n",
    "    \n",
    "    Returns: \n",
    "        If image found [{name,title,org_url='requesting url'},...]\n",
    "    \n",
    "    .. warning:: this fetches from wikipedia, requesting too frequenty is bad manners. Uses the lru_cache()\n",
    "    so it minimises the requests.\n",
    "    \n",
    "    \"\"\"\n",
    "    img_urls = list()\n",
    "    try:\n",
    "        r = requests.get(url = url)\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(\"Error request.get, url: {} except:{}\".format(url, str(e)))\n",
    "    else:\n",
    "        div = soup.find(\"div\", class_=\"fullImageLink\")\n",
    "        if (div is not None):\n",
    "            imgA = div.find(\"a\")\n",
    "            img_urls.append({\"title\":soup.title.getText(),\"img\":\"https:\" + imgA.attrs['href'],\"org_url\":url})\n",
    "        else: \n",
    "            print(\"failed to find div for\",url)\n",
    "    finally:\n",
    "        return img_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class soup_image_extract():\n",
    "    \"\"\"If the the field_name has a potential a image we\n",
    "    \n",
    "    Return: \n",
    "        None : field did not have potenital for an image.\n",
    "        [] : had potential but no url found. \n",
    "        [{title,img,href}]\n",
    "    \"\"\"\n",
    "    def __init__(self, field_name=\"title\", url_base=\"https://www.wikidata.org/wiki/\"):\n",
    "        self.url_base = url_base\n",
    "        self.field_name = field_name\n",
    "    \n",
    "    def __call__(self, _tuple):\n",
    "        title = _tuple[self.field_name]\n",
    "        img_desc = None \n",
    "        if (title[0] == \"Q\"):\n",
    "            lnk = self.url_base + title\n",
    "            img_desc = shred_item_image(lnk)\n",
    "        elif title.startswith(\"File:\") and (title.endswith('.JPG') or title.endswith('.jpg')):\n",
    "            lnk = self.url_base + title.replace(' ','_')\n",
    "            img_desc = shred_jpg_image(lnk)\n",
    "        _tuple['img_desc'] = img_desc\n",
    "        return _tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='composeBuildSubmit'></a>\n",
    "## Compose, build and submit the Streams application.\n",
    "The following Code cell composed the Streams application depicted here:\n",
    "![stillPhase3.jpg](images/stillPhase3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is notebook is an extention of the previous, I'll only discuss processing beyond 'langAugment' for details regarding prior processing refer to previous [notebook](./imgAna_2.ipynb)s.\n",
    "\n",
    "The events output by the map named 'langAugment' are limited to those with of type 'edit' and bot is 'False'. \n",
    "The fields are: code, delta_len, language, native, new_len, old_len, timestamp,\n",
    "title, user and wiki. This phase uses the 'title' field to build a url of a webpage, the webpage is feched and processed looking for a image URL. \n",
    "\n",
    "The map method named 'imageSoup'  invokes soup_image_extract() where it uses the 'title' field attempting to locate an image. If no image is found, None is returned and nothing flows out of the operator. \n",
    "If an image is found then the output includes a 'img_desc' field. A filter is applied to the 'img_desc' for content, \n",
    "if it does have content the tuple procedes to the view 'soupActive' where it can be viewed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef42c3170db445fac8482632808c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Cancel jobs(s)', layout=Layout(width='60%'), options=(), rows=0, value=()), ToggleButton(value=False, button_style='warning', description='Cancel', icon='stop', tooltip='Delete selected jobs')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_jobs(instance, cancel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WikiPhase3(jobName=None, wiki_lang_fname=None):\n",
    "    \"\"\"\n",
    "    Compose topology. \n",
    "    -- wiki_lang : csv file mapping database name to langauge\n",
    "\n",
    "    \"\"\"\n",
    "    topo = Topology(name=jobName)\n",
    "    ### make sure we sseclient in Streams environment.\n",
    "    topo.add_pip_package('sseclient')\n",
    "    topo.add_pip_package('bs4')\n",
    "\n",
    "    ## wiki events\n",
    "    wiki_events = topo.source(get_events, name=\"wikiEvents\")\n",
    "    ## select events generated by humans\n",
    "    human_filter = wiki_events.filter(lambda x: x['type']=='edit' and x['bot'] is False, name='humanFilter')\n",
    "    # pare down the humans set of columns\n",
    "    pared_human= human_filter.map(lambda x : {'timestamp':x['timestamp'],\n",
    "                                              'new_len':x['length']['new'],\n",
    "                                              'old_len':x['length']['old'], \n",
    "                                              'delta_len':x['length']['new'] - x['length']['old'],\n",
    "                                              'wiki':x['wiki'],'user':x['user'],\n",
    "                                              'title':x['title']}, \n",
    "                        name=\"paredHuman\")\n",
    "    pared_human.view(buffer_time=1.0, sample_size=200, name=\"paredEdits\", description=\"Edits done by humans\")\n",
    "\n",
    "    ## Define window(count)& aggregate\n",
    "    sum_win = pared_human.last(100).trigger(20)\n",
    "    sum_aggregate = sum_win.aggregate(sum_aggregation(sum_map={'new_len':'newSum','old_len':'oldSum','delta_len':'deltaSum' }), name=\"sumAggregate\")\n",
    "    sum_aggregate.view(buffer_time=1.0, sample_size=200, name=\"aggEdits\", description=\"Aggregations of human edits\")\n",
    "\n",
    "    ## Define window(count) & tally edits\n",
    "    tally_win = pared_human.last(100).trigger(10)\n",
    "    tally_top = tally_win.aggregate(tally_fields(fields=['user', 'title'], top_count=10), name=\"talliesTop\")\n",
    "    tally_top.view(buffer_time=1.0, sample_size=200, name=\"talliesCount\", description=\"Top count tallies: user,titles\")\n",
    "\n",
    "    ## augment filterd/pared edits with language\n",
    "    if cfg is None:\n",
    "        lang_augment = pared_human.map(wiki_lang(fname='../datasets/wikimap.csv'), name=\"langAugment\")\n",
    "    else:\n",
    "        lang_augment = pared_human.map(wiki_lang(fname=os.environ['DSX_PROJECT_DIR']+'/datasets/wikimap.csv'), name=\"langAugment\")\n",
    "    lang_augment.view(buffer_time=1.0, sample_size=200, name=\"langAugment\", description=\"Language derived from wiki\")\n",
    "\n",
    "    ## Define window(time) & tally language\n",
    "    time_lang_win = lang_augment.last(datetime.timedelta(minutes=2)).trigger(5)\n",
    "    time_lang = time_lang_win.aggregate(tally_fields(fields=['language'], top_count=10), name=\"timeLang\")\n",
    "    time_lang.view(buffer_time=1.0, sample_size=200, name=\"talliesTime\", description=\"Top timed tallies: language\")\n",
    "\n",
    "    ## attempt to extract image using beautifulsoup add img_desc[{}] field\n",
    "    soup_image = lang_augment.map(soup_image_extract(field_name=\"title\", url_base=\"https://www.wikidata.org/wiki/\"),name=\"imgSoup\")\n",
    "    soup_active = soup_image.filter(lambda x: x['img_desc'] is not None and len(x['img_desc']) > 0, name=\"soupActive\")\n",
    "    soup_active.view(buffer_time=1.0, sample_size=200, name=\"soupActive\", description=\"Image extracted via Bsoup\")\n",
    "\n",
    "\n",
    "    return ({\"topo\":topo,\"view\":{ }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting job : ICP or Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb48999677664d25b6a2b9172119e0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='Initializing', max=10, style=ProgressStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId:  10 Name:  ipythoninput113a4b30d5de96::WikiPhase3_10\n"
     ]
    }
   ],
   "source": [
    "resp = WikiPhase3(jobName=\"WikiPhase3\")\n",
    "if cfg is not None:\n",
    "    # Disable SSL certificate verification if necessary\n",
    "    cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "    submission_result = context.submit(\"DISTRIBUTED\",resp['topo'], config=cfg)\n",
    "\n",
    "if cfg is None:\n",
    "    import credential\n",
    "    cloud = {\n",
    "        context.ConfigParams.VCAP_SERVICES: credential.vcap_conf,\n",
    "        context.ConfigParams.SERVICE_NAME: \"Streaming3Turbine\",\n",
    "        context.ContextTypes.STREAMING_ANALYTICS_SERVICE:\"STREAMING_ANALYTIC\",\n",
    "        context.ConfigParams.FORCE_REMOTE_BUILD: True,\n",
    "    }\n",
    "    submission_result = context.submit(\"STREAMING_ANALYTICS_SERVICE\",resp['topo'],config=cloud)\n",
    "\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result.job:\n",
    "    print(\"JobId: \", submission_result['id'] , \"Name: \", submission_result['name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='viewingData'></a>\n",
    "## Viewing data \n",
    "\n",
    "The running application has number of views to see what what data is moving through the stream. The following \n",
    "cell will fetch the views' queue and display it's data when selected. \n",
    "\n",
    "|view name | description of data is the view | bot |\n",
    "|---------|-------------|------|\n",
    "|aggEdits  | summarised fields | False |\n",
    "|langAugment | mapped augmented fields | False |\n",
    "|paredEdits | seleted fields | False |\n",
    "|talliesCount | last 100 messages tallied | False | \n",
    "|talliesTimes | 2 minute windowed | False |\n",
    "|soupActive | extracted images links| False | \n",
    "\n",
    "\n",
    "You want to stop the the fetching the view data when done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acces Views / Render Views UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134e80f0e82f48b396ed21f71ad3c49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>RadioButtons</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "RadioButtons(description='Select view to display', options=('aggEdits', 'langAugment', 'paredEdits', 'soupActive', 'talliesCount', 'talliesTime'), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the views.....\n",
    "display_views(instance, job_name=\"WikiPhase3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render image submitted to wiki feed \n",
    "Build dashboard to display images are being submitted to Wikipedia. \n",
    "\n",
    "It's not uncommon to see the  same image multiple times. An image (any content) may need to be vetted for \n",
    "quailty, copyright, pornograpy etc... Each vet stage generating another event on the Stream\n",
    "\n",
    "A variety of images are submitted, unfortunaly not all images are rendered in all browsers. I found that the Safari \n",
    "browser and render .tif files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook support\n",
    "\n",
    "def render_image(image_url=None, output_region=None):\n",
    "    \"\"\"Write the image into a output region.\n",
    "    \n",
    "    Args::\n",
    "        url: image\n",
    "        output_region: output region\n",
    "        \n",
    "    .. note:: The creation of the output 'stage', if this is not done the image is rendered in the page and\n",
    "        the output region. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        stage = widgets.Output(layout={'border': '1px solid green'})\n",
    "    except:\n",
    "        print(\"Error on request : \", image_url)\n",
    "    else:\n",
    "        if response.status_code == 200:\n",
    "            with output_region:\n",
    "                stage.append_display_data(widgets.Image(\n",
    "                    value=response.content,\n",
    "                    #format='jpg',\n",
    "                    width=300,\n",
    "                    height=400,\n",
    "                ))\n",
    "            output_region.clear_output(wait=True) \n",
    "\n",
    "ana_stage = list()\n",
    "def display_image(tup, image_region=None, title_region=None, url_region=None):\n",
    "    if tup['img_desc'] is not None and len(tup['img_desc']) > 0:\n",
    "        display_desc = tup['img_desc'][0]\n",
    "        ana_stage.append(display_desc)\n",
    "        title_region.value = \"Img Title:{}\".format(display_desc['title'] )\n",
    "        url_region.value = \"{}\".format(display_desc['img'])\n",
    "        render_image(image_url=display_desc['img'], output_region=image_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show me now\n",
    "<a id='showMeNow'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cb8d388212469792720aeb9d315edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Label(value='Status', layout=Layout(border='1px solid green', width='30%')), Output(layout=Layout(border='1px solid red', height='270pt', width='30%')), Label(value='Title', layout=Layout(border='1px solid green', width='30%')), Label(value='Img URL', layout=Layout(border='1px solid green', width='100%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Setup the Dashboard - display images sent to Wikipedia \n",
    "##                         Next cell populates the 'Dashboard'.....\n",
    "status_widget = widgets.Label(value=\"Status\", layout={'border': '1px solid green','width':'30%'})\n",
    "url_widget = widgets.Label(value=\"Img URL\", layout={'border': '1px solid green','width':'100%'})\n",
    "image_widget = widgets.Output(layout={'border': '1px solid red','width':'30%','height':'270pt'})\n",
    "title_widget = widgets.Label(value=\"Title\", layout={'border': '1px solid green','width':'30%'})\n",
    "\n",
    "dashboard = widgets.VBox([status_widget, image_widget, title_widget, url_widget])\n",
    "display(dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook support\n",
    "# setup \n",
    "_view = instance.get_views(name=\"soupActive\")[0]\n",
    "_view.start_data_fetch()\n",
    "\n",
    "@catchInterrupt\n",
    "def server_soup(count=25):\n",
    "    \"\"\"Fetch and display images from view.\n",
    "    Args::\n",
    "        count: number of iterations to fetch images, count<0\n",
    "        is infinite\n",
    "    \"\"\"\n",
    "    while count != 0:\n",
    "        count -= 1\n",
    "        view_tuples = _view.fetch_tuples(max_tuples=100, timeout=2)\n",
    "        for soup_tuple in view_tuples:\n",
    "            status_widget.value = soup_tuple['title']\n",
    "            display_image(soup_tuple, image_region=image_widget, title_region=title_widget, url_region=url_widget)\n",
    "\n",
    "server_soup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel jobs when your done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_jobs(instance, cancel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook wrap up.Â¶\n",
    "In  notebook composed and deployed a Streams application that processes live Wikipedia events on a server. It \n",
    "extended the previous application to extract images assocated with the event. In the case that the event\n",
    "does have an associated image, it pushed out to a view where it was rendered. \n",
    "\n",
    "\n",
    "In the next notebook we will continue the build out, using the extraced image we'll  apply AI image processing to extract out faces an score them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
