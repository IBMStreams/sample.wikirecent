{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "You'll find two complete components in this directory. \n",
    "\n",
    "- Video Image Processing - Extract faces and objects from video. \n",
    "- Wikipedia Tutorial - Analysis of WikiPedia updates\n",
    "\n",
    "Video Image processing accepts frames from video feeds, sending each through a model that extracts regions of interest. If and image has a region of interest it is displayed in the notebook. The images flow into the model via pub/sub interface, the initial publisher is Kafka.\n",
    "\n",
    "Wikipedia has SSE interface that it pubishes all updates on, updates are driven by users making changing to cotent and 'robots' monitoring. Robots monitor for copyright infringment, site descecration, fact checking, improper language, image cropping etc. The Wikipedia tutorial goes through a number of step at each a graph or display is rendered reflecting what is currently being processed. The steps include - \n",
    "\n",
    "\n",
    "The final phase 'Wikipedia Tutorial' is performed by phases in the 'Video Image Processing' by publishing images \n",
    "to the same topic as Kafka receiever in 'Video Image Processing\n",
    "\n",
    "\n",
    "## Why 2 Components\n",
    "\n",
    "The 'Wikipedia Tutorial' component is a realistic processing of a feed which it walks through :\n",
    "- Connecting to the wikipedia feed using SSE, a standard web interface similar to WebSocket but not as well known.\n",
    "- Break out requests generated by robots or non-robots.\n",
    "- Break out the countries the submission are currently submitted from. Majority of submissions come in the countries evening. \n",
    "- Capture top submitters. \n",
    "- Extracting web content with Beautiful Soup, a beguiling named Python package used to shred web content.\n",
    "- Fetching image content using the Python Requests package.\n",
    "- Extracting faces .\n",
    "- Extracting objects.\n",
    "\n",
    "This processing is built up accross 4 notebooks, which is a hard to slog through if you just want to \n",
    "get a feel for the capabilities. Thus the 'Video Image Processing', the majority of the processing \n",
    "is a ML BlackBox that extracts regions of interest. Easy to get taste of the capabilities with minimal \n",
    "investment. \n",
    "\n",
    "An added benifit, the 'Wikipedia Extraction' puplishes to the same topic as the Kafka component, no additional setup \n",
    "if you done the more interesting (Video) component first. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graph of application](images/imageOnlyApplications.png)\n",
    "\n",
    "This demostration is made up of two Notebook. \n",
    "- [croppedCamSender](croppedCamSender.ipynb) : generate frames from video\n",
    "- [vidoeImageAnalysis](videoImageAnalysis.jupyter-py36.ipynb) : accept images, process with BlackBox ML\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## WikiPedia Tutorial\n",
    "\n",
    "The notebooks in this project compose real-time streaming analysis applications that use live Wikipedia data. The initial notebook \n",
    "demonstrates connecting to a datasource (Wikipedia), filtering updates and viewing the data in the browser. The\n",
    "final notebook applies multiple levels of AI models to locate, extract and score live updates from Wikipedia data.\n",
    "\n",
    "Each notebook composes, submits and renders the results as a standalone application. There are\n",
    "no code dependencies between notebooks. \n",
    "\n",
    "\n",
    "\n",
    "## Collection of links to Streams and ICP4D resources\n",
    "- [MediaWiki sse feed](https://stream.wikimedia.org/v2/stream/recentchange)\n",
    "- [MediaWiki explanation of feed](https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams)\n",
    "- [Invoking SPL operators](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.spl.op.html#module-streamsx.spl.op)\n",
    "- [Topology](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html?highlight=window#streamsx.topology.topology.Topology)\n",
    "\n",
    "\n",
    "## imgAna_0\n",
    "- Access the wiki data using SSE directly in Python\n",
    "- Render update type (new, edit, update, log) counts in a graph\n",
    "\n",
    "## imgAna_1\n",
    "![stillPhase1](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase1.jpg)\n",
    "- Access the wiki live data streams via SSE\n",
    "- Filter out messages that were generated by bots\n",
    "- View the live data in the notebook\n",
    "\n",
    "## imgAna_2 \n",
    "![stillPhase](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase2.jpg)\n",
    "\n",
    "Access the wiki data with the benefit of Streams. \n",
    "- Building on the previous notebook\n",
    "- Normalize the language of submission\n",
    "- Aggregate the top 10 submitters in the last 10 minutes: time-based windowing\n",
    "- Aggregate the top articles in the last 200 submissions: event-based windowing\n",
    "- View live data in notebook, top articles and languages in a \"dashboard\"\n",
    "\n",
    "## imgAna_3\n",
    "![stillPhase3](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase3.jpg)\n",
    "- Building on the previous notebook\n",
    "- Analyze wiki updates to find image links\n",
    "- Shred pages using a Python package (beautifulsoup)  \n",
    "- View live data in notebook, render images submitted to Wikipedia\n",
    "\n",
    "## imgAna_4 - incorrect graph/explaination ** FIX **\n",
    "![stillPhase4](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase4.jpg)\n",
    "- Building on the previous notebook\n",
    "- Run extracted images through the Facial Recognizer model and derive cropped facial image\n",
    "- Run cropped facial images through the Facial Emotion Classifier to generate a score\n",
    "- View live data in notebook, render submitted image, scored, cropped and classified by emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
