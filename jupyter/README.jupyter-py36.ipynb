{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "You'll find two complete components in this directory, that can merge into one. \n",
    "\n",
    "- Video Image Processing - Extract faces and objects from video. \n",
    "- Wikipedia Tutorial - Analysis of WikiPedia updates\n",
    "\n",
    "Video Image processing accepts frames from video feeds, sending each through a model that extracts regions of interest. If an image has a region of interest it is displayed in the notebook. The images flow into the model via pub/sub interface, the initial publisher is Kafka.\n",
    "\n",
    "Wikipedia has SSE interface that it pubishes all updates on, updates are driven by users making changing to cotent and 'robots' monitoring. Robots monitor for copyright infringment, site descecration, fact checking, improper language, image cropping etc. The Wikipedia tutorial goes through a number of step at each a graph or display is rendered reflecting what is currently being processed. The steps include - \n",
    "\n",
    "The final phase 'Wikipedia Tutorial' is performed by phases in the 'Video Image Processing' by publishing images \n",
    "to the same topic as Kafka receiever in 'Video Image Processing\n",
    "\n",
    "\n",
    "## Why two Components\n",
    "\n",
    "The 'Wikipedia Tutorial' component is a 'realistic' processing of a live feed, phases include :\n",
    "- Connecting to the wikipedia feed using SSE, a standard web interface similar to WebSocket but not as well known.\n",
    "- Break out requests generated by robots or non-robots.\n",
    "- Break out the countries the submission are currently submitted from. Majority of submissions come in the countries evening. \n",
    "- Capture top submitters. \n",
    "- Extracting web content with Beautiful Soup, a beguiling named Python package used to shred web content.\n",
    "- Fetching image content using the Python Requests package.\n",
    "- Extracting faces.\n",
    "- Extracting objects.\n",
    "\n",
    "This processing is built up across 4 notebooks, which is a hard to slog through if you just want to \n",
    "get a feel for the capabilities. Thus the 'Video Image Processing', the majority of the processing \n",
    "is a ML BlackBox that extracts regions of interest. Easy to get taste of the capabilities with minimal \n",
    "investment. \n",
    "\n",
    "An added benifit, the 'Wikipedia Extraction' publishes to the same topic as the Kafka component, \n",
    "no additional setup if you done the more interesting (Video) component first. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "### Imports \n",
    "The following collects all the packages used by the notebooks broken down when they are first required.\n",
    "##### Notebook : imagAna_0\n",
    "- pip install SSEClient===0.0.22 --upgrade --user\n",
    "- pip install pillow\n",
    "- pip install matplotlib\n",
    "- pip install ipywidgets\n",
    "- pip install pandas\n",
    "\n",
    "\n",
    "##### Notebook: imagAna1\n",
    "- pip install --user --upgrade streamsx\n",
    "\n",
    "##### Notebook: imagAna2\n",
    "\n",
    "##### Notebook : imageAna3\n",
    "- \n",
    "pip install beautifulsoup4\n",
    "\n",
    "\n",
    "##### Notebook : videoImageAnalysis\n",
    "- pip install opencv-python\n",
    "- pip install kafka-python\n",
    "\n",
    "##### Notebook : croppedCamSender\n",
    "- pip install m3u8\n",
    "- pip install interactivecrop\n",
    "\n",
    "\n",
    "### Kafka :\n",
    "The Video Image Processing uses Kafka to transmit video components to the Streams application. \n",
    "The images are being transmitted from notebook (croppedCamSender) running in the Juypter notebook (locally) to the Streams instance in the Cloud. \n",
    "\n",
    "This uses Cloud Kafka aka MessageHub i\n",
    "The following walks though setting up and configuring the Kafka service. \n",
    "\n",
    "### Model Usage : \n",
    "\n",
    "Their are two Image analysis phases: locate faces and locate objects. I treat the models as a BlackBox, images go into and a score comets out of. The develolment of the models can be found [here](here). You will need to download the models from the project and copy them into a directory where the Streams deployment will upload them. \n",
    "\n",
    "The code is using the YOLOv3 model, based upon this [note](https://blog.roboflow.ai/yolov5-is-here/) it is evolving. \n",
    "\n",
    "\n",
    "Details of where to copy the files will e found in the videoImageAnalysis notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graph of application](images/imageOnlyApplications.png)\n",
    "\n",
    "This demonstration is made up of two Notebooks. \n",
    "- [croppedCamSender](croppedCamSender.ipynb) : generate frames from video\n",
    "- [vidoeImageAnalysis](videoImageAnalysis.jupyter-py36.ipynb) : accept images, process with BlackBox ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## WikiPedia Tutorial\n",
    "\n",
    "The notebooks in this project compose real-time streaming analysis applications that use live Wikipedia data. The initial notebook \n",
    "demonstrates connecting to a datasource (Wikipedia), filtering updates and viewing the data in the browser. The\n",
    "final notebook applies multiple levels of AI models to locate, extract and score live updates from Wikipedia data.\n",
    "\n",
    "Each notebook composes, submits and renders the results as a standalone application. There are\n",
    "no code dependencies between notebooks. \n",
    "\n",
    "\n",
    "\n",
    "## Collection of links to Streams and ICP4D resources\n",
    "- [MediaWiki sse feed](https://stream.wikimedia.org/v2/stream/recentchange)\n",
    "- [MediaWiki explanation of feed](https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams)\n",
    "- [Invoking SPL operators](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.spl.op.html#module-streamsx.spl.op)\n",
    "- [Topology](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html?highlight=window#streamsx.topology.topology.Topology)\n",
    "\n",
    "\n",
    "## imgAna_0\n",
    "- Access the wiki data using SSE directly in Python\n",
    "- Render update type (new, edit, update, log) counts in a graph\n",
    "\n",
    "## imgAna_1\n",
    "![stillPhase1](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase1.jpg)\n",
    "- Access the wiki live data streams via SSE\n",
    "- Filter out messages that were generated by bots\n",
    "- View the live data in the notebook\n",
    "\n",
    "## imgAna_2 \n",
    "![stillPhase](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase2.jpg)\n",
    "\n",
    "Access the wiki data with the benefit of Streams. \n",
    "- Building on the previous notebook\n",
    "- Normalize the language of submission\n",
    "- Aggregate the top 10 submitters in the last 10 minutes: time-based windowing\n",
    "- Aggregate the top articles in the last 200 submissions: event-based windowing\n",
    "- View live data in notebook, top articles and languages in a \"dashboard\"\n",
    "\n",
    "## imgAna_3\n",
    "![stillPhase3](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase3.jpg)\n",
    "- Building on the previous notebook\n",
    "- Analyze wiki updates to find image links\n",
    "- Shred pages using a Python package (beautifulsoup)  \n",
    "- View live data in notebook, render images submitted to Wikipedia\n",
    "\n",
    "## imgAna_4 - incorrect graph/explaination ** FIX **\n",
    "![stillPhase4](https://github.com/IBMStreams/sample.wikirecent/raw/master/jupyter/images/stillPhase4.jpg)\n",
    "- Building on the previous notebook\n",
    "- Run extracted images through the Facial Recognizer model and derive cropped facial image\n",
    "- Run cropped facial images through the Facial Emotion Classifier to generate a score\n",
    "- View live data in notebook, render submitted image, scored, cropped and classified by emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
