{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "You'll find two major components in this directory, that can merge into one. \n",
    "\n",
    "- [Video Image Analysis](videoImageAnalysis.jupyter-py36.ipynb)(VIA) : Extract objects from video. \n",
    "- [Live Wiki Extract](liveWikiExtract.jupyter-py36.ipynb): Analysis of current WikiPedia updates.\n",
    "\n",
    "Video Image Analysis creates a Streams application that accepts images and extracts objects using an open sourced ML code. The notebook composes and submits the application, images that have objects recognized by the ML module can be rendered in the notebook. The images arrive on the 'image_active' topic.\n",
    "\n",
    "Two source of images are provided :\n",
    "- 'Live Wiki Extract' notebook monitors [Wikimedia EventStreams](https://stream.wikimedia.org/?doc) where updates to Wikipedia are published as they arrive. The notebook goes through multi step process of extracting and characteriing updates,  eventually getting to images which are published to the 'image_active' topic.\n",
    "- The [Cropped Image Sender](croppedImageSender.ipynb) extracts frames from mpeg videos and pumps them to streams via Kafka. The recieving side on Streams, accepts the frames publishes them on the 'image_active' topic. \n",
    "\n",
    "Images that are source from the wikipidiea or video stream are processed and rendered by the 'Video Image Analysis' notebook.\n",
    "- \n",
    "\n",
    "\n",
    "## Two Components\n",
    "\n",
    "The 'Live Wiki Extract' notebook is a 'realistic' processing of a live feed, phases include :\n",
    "- Connecting to the wikipedia feed using SSE (web standard similar to WebSocket).\n",
    "- Break out requests generated by robots or non-robots.\n",
    "- Break out the countries the submission are currently submitted from. Majority of submissions come in the countries evening. \n",
    "- Capture top submitters. \n",
    "- Extracting web content with Beautiful Soup, a beguiling named Python package used to shred web content.\n",
    "- Fetching image content using the Python Requests package.\n",
    "- publishing images for further processing on the 'image_active' topic.\n",
    "\n",
    "This processing is built on relativly notebook composed of mulitple applications that communicate via pub/sub. A hard to slog for the curious but practical. \n",
    "\n",
    "The 'Video Image Processing' accepts images on the 'image_active' topic and use open source ML to analyze. A relativly short piece of code that illustrates how to intergrate a ML 'BlackBox'. 'BlackBox' box in this context mean blackbox since I found the model and moved it over - links to the description of how it's generated can be found in the notebook.\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "### Imports \n",
    "The following collects all the packages used by the notebooks broken down when they are first required.\n",
    "##### Notebook : imagAna_0\n",
    "- pip install SSEClient===0.0.22 --upgrade --user\n",
    "- pip install pillow\n",
    "- pip install matplotlib\n",
    "- pip install ipywidgets\n",
    "- pip install pandas\n",
    "\n",
    "\n",
    "##### Notebook: liveWikiExtract\n",
    "- pip install --user --upgrade streamsx\n",
    "- pip install beautifulsoup4\n",
    "- pip install opencv-python\n",
    "- pip install kafka-python\n",
    "\n",
    "##### Notebook : croppedImageSender\n",
    "- pip install m3u8\n",
    "- pip install interactivecrop\n",
    "\n",
    "\n",
    "## Credentials \n",
    "\n",
    "\n",
    "\n",
    "The applications use two Cloud resources. This will go though creating resources, fetching the credentials and setting up the scripts/credentials.py file. All the notebooks use something from the credential.py. \n",
    "\n",
    "\n",
    "### Streams - \n",
    "\n",
    "Using your IBM Cloud a account create a Lite [Streaming Analytics](https://cloud.ibm.com/catalog/services/streaming-analytics) service. \n",
    "-  When if finishes provisioning access the newly created resource. Select the 'Service credentials' to bring up the 'Service credentials' pane. \n",
    "- Create the credential by selecting 'New credential'\n",
    "- Select the newly created credential's 'copy to clipboard' on the right\n",
    "- Paste the copied text into the cell below, this will be used when we build the credentials file below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ovewrite with Streams credential**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Streams  aka Kafka\n",
    "Using your IBM Clound account create a Lite [Event Streams](https://cloud.ibm.com/catalog/services/event-streams) service.\n",
    "- When finished provisioning access the newly created resource. Select the 'Manage' to bring up the managment pane. \n",
    "- Select 'Create a topic'\n",
    "- Enter 'VideoFrame' for the topic name and select 'Next'\n",
    "- Select 'Next' and 'Create topic' with the defaule values.\n",
    "- You will be retrned to your instance's resource entry. \n",
    "- Select the 'Service credentials' to bring up the 'Service credentials' pane. \n",
    "- Create the credential by selecting 'New credential'\n",
    "- Select the newly created credential's 'copy to clipboard' on the right\n",
    "- Paste the copied text into the cell below, this will be used when we build the credentials file below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ovewrite with Event Streams credential**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update and rename credentialSetup.py\n",
    "\n",
    "- Open 'script/credentialSet.py' file. \n",
    "- Paste the Streams and Event Streams credentials from above into the areas specified within the file. \n",
    "- Save the updated \n",
    "- Rename the file credential.py, do not check in the file to git. \n",
    "\n",
    "The credential.py is accessed when submitting Steams jobs and utilizing the Event Streams facility.\n",
    "\n",
    "\n",
    "\n",
    "## Installing the yolov3.weights : \n",
    "\n",
    "Their are two Image analysis phases: locate faces and locate objects. I treat the models as a BlackBox, images go in and a score comes out. The development of the models can be found below. You will need to download the yolo3.weights files it's beyond the capacity of git.  \n",
    "\n",
    "Download https://pjreddie.com/media/files/yolov3.weights and copy it into datasets directory with the other yolov3 files. \n",
    "\n",
    "\n",
    "[Yolo3](https://www.learnopencv.com/deep-learning-based-object-detection-using-yolov3-with-opencv-python-c/)\n",
    "\n",
    "The code is using the YOLOv3 model, based upon this [note](https://blog.roboflow.ai/yolov5-is-here/) it is evolving. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
