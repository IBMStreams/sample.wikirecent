{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiRecentPhase1 - \n",
    "\n",
    "\n",
    "## Continious processing with Streams.\n",
    "\n",
    "[WikiRecentPhase0](imgAna_0.jupyter-py36.ipynb) illustrated accessing continious streams events from a notebook in Python as a way to explore the nature of the data and to understand how to develop it into useful insights. In that exploration data is collected, averages are calculated only as long as the notebook open and specific cells are running. That model makes it challenging to make business use of insights derived from the stream.\n",
    "\n",
    "\n",
    "In this notebook we will transition the work we did with the data in step 0 to a continuously running Streams job, develop the insights further and show how the Notebook can be used to access the outputs of the job for user visualization and action.\n",
    "\n",
    "## Overview \n",
    "**About the sample** \n",
    "\n",
    "The appliction recieves Wikipedia updates as events via SSE. An event\n",
    "has a 'bots' field indicating that it was generated by a robot. Many robots exist Wikipedia to perform\n",
    "mandane checking tasks: checking, copyright infringment,inappropriate content...\n",
    "This application will focus on messages generated by humans filtering out those from 'bots'. \n",
    "The event has a number of superflous fields that are removed before it is presented to 'view'. \n",
    "\n",
    "A 'view'enables a developer to observe data that is flowing through the live stream, data presented to the \n",
    "view is available for display over the web. Due to the realtime nature of Streams the view may and the \n",
    "limitations of web communcations a view will drop observations as resources (CPU, memory, bandwidy) become limited. \n",
    "This has not been an issue with this suite of notebooks.\n",
    "\n",
    "The application is composed and submitted from the notebook, it runs on a server continiously until it is stopped. \n",
    "This notebook accesses and renders view data in order to see how the Streams is processing the events \n",
    "recieved from Wikipedia. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n",
    "- [Topology](https://streamsxtopology.readthedocs.io/en/latest/index.html) Streams Topology documentation\n",
    "- [Widgets](https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Basics.html) Notebook Widgets documentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Submit the appplication that has a filter. \n",
    "\n",
    "- rough cut look at the data\n",
    "- plot the 'type' data\n",
    "- look at the filtered data\n",
    "\n",
    "##  Collect in buffer / Aggregate\n",
    "- Last 1000 in local buffer & aggregate\n",
    "- Render\n",
    "- Push code to server.\n",
    "\n",
    "\n",
    "<a name=\"setup\"></a>\n",
    "# Setup\n",
    "### Add credentials for the IBM Streams service\n",
    "\n",
    "#### ICPD setup\n",
    "\n",
    "With the cell below selected, click the \"Connect to instance\" button in the toolbar to insert the credentials for the service.\n",
    "\n",
    "<a target=\"blank\" href=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/02/connect_icp4d.gif\">See an example</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from icpd_core import icpd_util\n",
    "cfg=icpd_util.get_service_instance_details(name='zen-sample-icp1-blitz-env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud setup\n",
    "\n",
    "To use Streams instance running in the cloud setup a [credential.py](setup_credential.ipynb)\n",
    "\n",
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Install components\n",
    "!pip --user install SSEClient===0.0.22 --upgrade\n",
    "!pip install --user --upgrade streamsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial imports are in support of accessing Streams with Wikipedia data, \n",
    "subsequent are in support of rendering the results as they flow back from \n",
    "Streams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Operational \n",
    "from streamsx.topology.topology import *\n",
    "import streamsx.rest as rest\n",
    "import streamsx.topology.context\n",
    "\n",
    "from sseclient import SSEClient as EventSource\n",
    "\n",
    "import urllib3\n",
    "\n",
    "## Renderng\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from statistics import mean\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, HBox, VBox, Layout\n",
    "%matplotlib inline\n",
    "\n",
    "from streamsx.topology import context\n",
    "\n",
    "print(\"streamsx package version: \" + streamsx.topology.context.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions used in interfacing  to Streams  \n",
    "Make interacting with the Streams data friendlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def catchInterrupt(func):\n",
    "    \"\"\"decorator : when interupt occurs the display is lost if you don't catch it\n",
    "       TODO * <view>.stop_data_fetch()  # stop\n",
    "       \n",
    "    .\"\"\"\n",
    "    def catch_interrupt(*args, **kwargs):\n",
    "        try: \n",
    "            func(*args, **kwargs)\n",
    "        except (KeyboardInterrupt): pass\n",
    "    return catch_interrupt\n",
    "\n",
    "\n",
    "def display_view_stop(eventView, period=2):\n",
    "    \"\"\"Wrapper for streamsx.rest_primitives.View.display() to have button. \"\"\"\n",
    "    button =  widgets.Button(description=\"Stop Updating\")\n",
    "    display(button)\n",
    "    eventView.display(period=period) \n",
    "    def on_button_clicked(b):\n",
    "        eventView.stop_data_fetch()\n",
    "        b.description = \"Stopped\"\n",
    "    button.on_click(on_button_clicked)\n",
    "\n",
    "def view_events(views):\n",
    "    \"\"\"\n",
    "    Build interface to display a list of views and \n",
    "    display view when selected from list.\n",
    "     \n",
    "    \"\"\"\n",
    "    view_names = [view.name for view in views]\n",
    "    nameView = dict(zip(view_names, views))    \n",
    "    select = widgets.RadioButtons(\n",
    "        options = view_names,\n",
    "        value = None,\n",
    "        description = 'Select view to display',\n",
    "        disabled = False\n",
    "    )\n",
    "    def on_change(b):\n",
    "        if (b['name'] == 'label'):\n",
    "            clear_output(wait=True)\n",
    "            [view.stop_data_fetch() for view in views ]\n",
    "            display(select)\n",
    "            display_view_stop(nameView[b['new']], period=2)\n",
    "    select.observe(on_change)\n",
    "    display(select)\n",
    "\n",
    "def find_job(instance, job_name=None):\n",
    "    \"\"\"locate job within instance\"\"\"\n",
    "    for job in instance.get_jobs():    \n",
    "        if job.applicationName.split(\"::\")[-1] == job_name:\n",
    "            return job\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_view(instance, job_name=None, view_name=\"view\"):\n",
    "    job = find_job(instance, job_name)\n",
    "    return job.get_views(view_name)\n",
    "    \n",
    "\n",
    "def display_views(instance, job_name):\n",
    "    \"Locate/promote and display all views of a job\"\n",
    "    job = find_job(instance, job_name=job_name)\n",
    "    if job is None:\n",
    "        print(\"Failed to locate job\")\n",
    "    else:\n",
    "        views = job.get_views()\n",
    "        view_events(views)\n",
    "        \n",
    "def list_jobs(_instance=None, cancel=False):\n",
    "    \"\"\"\n",
    "    Interactive selection of jobs to cancel.\n",
    "    \n",
    "    Prompts with SelectMultiple widget, if thier are no jobs, your presente with a blank list.\n",
    "    \n",
    "    \"\"\"\n",
    "    active_jobs = { \"{}:{}\".format(job.name, job.health):job for job in _instance.get_jobs()}\n",
    "\n",
    "    selectMultiple_jobs = widgets.SelectMultiple(\n",
    "        options=active_jobs.keys(),\n",
    "        value=[],\n",
    "        rows=len(active_jobs),\n",
    "        description = \"Cancel jobs(s)\" if cancel else \"Active job(s):\",\n",
    "        layout=Layout(width='60%')\n",
    "    )\n",
    "    cancel_jobs = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description='Cancel',\n",
    "        disabled=False,\n",
    "        button_style='warning', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Delete selected jobs',\n",
    "        icon=\"stop\"\n",
    "    )\n",
    "    def on_value_change(change):\n",
    "        for job in selectMultiple_jobs.value:\n",
    "            print(\"canceling job:\", job, active_jobs[job].cancel())\n",
    "        cancel_jobs.disabled = True\n",
    "        selectMultiple_jobs.disabled = True\n",
    "\n",
    "    cancel_jobs.observe(on_value_change, names='value')\n",
    "    if cancel:\n",
    "        return HBox([selectMultiple_jobs, cancel_jobs])\n",
    "    else:\n",
    "        return HBox([selectMultiple_jobs])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the server :  ICP4D or Cloud instance -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_instance():\n",
    "    \"\"\"Setup to access your Streams instance.\n",
    "\n",
    "    ..note::The notebook is work within Cloud and ICP4D. \n",
    "            Refer to the 'Setup' cells above.              \n",
    "    Returns:\n",
    "        instance : Access to Streams instance, used for submitting and rendering views.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from icpd_core import icpd_util\n",
    "        import urllib3\n",
    "        global cfg\n",
    "        cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "        instance = rest.Instance.of_service(cfg)\n",
    "        print(\"Within ICP4D\")\n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    except ImportError:\n",
    "        cfg = None\n",
    "        print(\"Outside ICP4D\")\n",
    "        import credential  \n",
    "        sc = rest.StreamingAnalyticsConnection(service_name='Streaming3Turbine', \n",
    "                                               vcap_services=credential.vcap_conf)\n",
    "        instance = sc.get_instances()[0]\n",
    "    return instance,cfg\n",
    "\n",
    "instance,cfg = get_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List jobs to cancel....\n",
    "This page will submit a job named 'WikiPhase1'. If it's running you'll want to cancel it before submitting a new version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "list_jobs(instance, cancel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composing the Streams application\n",
    "- get data from wiki usng SSE\n",
    "- filter data, seperate out the humans and RObots\n",
    "- setup views : allEvents, allHumans, paredHumans, paredAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive messages updates from Wikipedia\n",
    "As updates are made to Wikipidia pages the changs are sent over and SSE feed. The get_events() function recieves the events and acting as a [source](https://streamsxtopology.readthedocs.io/en/latest/streamsx.topology.topology.html#streamsx.topology.topology.Topology.source) pushes them onto the Streams streams.\n",
    "\n",
    "This is functional the same code as the 'imgAna0' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_events():\n",
    "    \"\"\"fetch recent changes from wikievents site using SSE\"\"\"\n",
    "    for change in EventSource('https://stream.wikimedia.org/v2/stream/recentchange'):\n",
    "        if len(change.data):\n",
    "            try:\n",
    "                obj = json.loads(change.data)\n",
    "            except json.JSONDecodeError as err:\n",
    "                print(\"JSON l1 error:\", err, \"Invalid JSON:\", change.data)\n",
    "            except json.decoder.JSONDecodeError as err:\n",
    "                print(\"JSON l2 error:\", err, \"Invalid JSON:\", change.data)\n",
    "            else:\n",
    "                yield(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter messages\n",
    "The [filter](https://streamsxtopology.readthedocs.io/en/latest/streamsx.topology.topology.html#streamsx.topology.topology.Stream.filter) is used to break out messages not generated by robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View into the live stream\n",
    "The [view](https://streamsxtopology.readthedocs.io/en/latest/streamsx.topology.topology.html#streamsx.topology.topology.Stream.view) enables access to live stream at runtime. We spread them liberaly throughout the application to observe how the processing is procedeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='composeBuildSubmit'></a>\n",
    "## Compose, build and submit the Streams application.Â¶\n",
    "\n",
    "The following Code cell composes the Streams application depicted here:\n",
    "\n",
    "![graph of application](images/stillPhase1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a single event source (wikiEvents)' we are creating a topology that delivers two streams of derived information.\n",
    "To make each step in this process accessible to examination we are declaring a view at each stage to look at the raw data and also to attach graphical visualizations. \n",
    "\n",
    "A Steams flow is composed by linking operator outputs to inputs.\n",
    "\n",
    "Two streams are being composed and three views are exposed\n",
    "\n",
    "1) All source events are sent to 'allEvents' view where they are exposed for viewing.\n",
    "\n",
    "2) All the source events sent to 'paredAll', where they are pared down to 6 fields and exposed for viewing. \n",
    "- the Wikipeida events are output from the 'source' method named 'wikiEvents on 'wiki_events' \n",
    "- the input to the 'map' method named 'paredAll'is wiki_events where fields  ('timestamp',type','wiki','bot','user','title') are extracted and output to 'pared_all'. \n",
    "- the input to 'view' method is 'named allEvents is 'pared_all' where the are exposed for viewing. \n",
    "\n",
    "3) All the source events are sent to 'humansOnly' that drops 'bot' fields of False, they are then are pared down to 5 fields and exposed for viewing.\n",
    "- the Wikipeida events are output from the 'source' method named 'wikiEvents on 'wiki_events' \n",
    "- the input to the 'filter' method named 'humanFilter' only events in whih the 'bot' field set to False are output on all_human. \n",
    "- the input to the 'map' method named 'paredHuman' is all_human where fields  ('timestamp',type','wiki','user','title') are extracted and output to 'pared_human'. \n",
    "- the input to 'view' method is named 'paredHuman' is 'pared_human' where the are exposed for viewing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def WikiPhase1(jobName=None):\n",
    "    \"\"\"\n",
    "    Compose topology \n",
    "\n",
    "    \"\"\"\n",
    "    topo = Topology(name=jobName)\n",
    "    topo.add_pip_package('SSEClient===0.0.22')\n",
    "\n",
    "    ## Receive wiki data \n",
    "    wiki_events = topo.source(get_events, name=\"wikiEvents\")\n",
    "    wiki_events.view(buffer_time=1.0, sample_size=1, name=\"allEvents\", description=\"All wiki events\")\n",
    "    \n",
    "    ## drop fields \n",
    "    pared_all = wiki_events.map(lambda x : {'timestamp':x['timestamp'],'type':x['type'],'wiki':x['wiki'],'bot':x['bot'],'user':x['user'],'title':x['title']}, name=\"paredAll\")\n",
    "    pared_all.view(buffer_time=1.0, sample_size=200, name=\"paredAll\", description=\"All events pared\")\n",
    "    \n",
    "    ## Filter out bots \n",
    "    all_human = wiki_events.filter(lambda x: x['bot'] is False, name='humanFilter')\n",
    "\n",
    "    ## drop fields\n",
    "    pared_human = all_human.map(lambda x : {'timestamp':x['timestamp'],'type':x['type'],'wiki':x['wiki'],'user':x['user'],'title':x['title']}, name=\"paredHuman\")\n",
    "    pared_human.view(buffer_time=1.0, sample_size=200, name=\"paredHuman\", description=\"Human events pared\")\n",
    "    \n",
    "    return ({\"topo\":topo})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit topology : build/submit (ICP4D or Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "resp = WikiPhase1(jobName=\"WikiPhase1\")\n",
    "if cfg is not None:\n",
    "    # Disable SSL certificate verification if necessary\n",
    "    cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "    submission_result = context.submit(\"DISTRIBUTED\",resp['topo'], config=cfg)\n",
    "\n",
    "if cfg is None:\n",
    "    import credential\n",
    "    cloud = {\n",
    "        context.ConfigParams.VCAP_SERVICES: credential.vcap_conf,\n",
    "        context.ConfigParams.SERVICE_NAME: \"Streaming3Turbine\",\n",
    "        context.ContextTypes.STREAMING_ANALYTICS_SERVICE:\"STREAMING_ANALYTIC\",\n",
    "        context.ConfigParams.FORCE_REMOTE_BUILD: True,\n",
    "    }\n",
    "    submission_result = context.submit(\"STREAMING_ANALYTICS_SERVICE\",resp['topo'],config=cloud)\n",
    "\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result.job:\n",
    "    print(\"JobId: \", submission_result['id'] , \"Name: \", submission_result['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='viewingData'></a>\n",
    "## Viewing data \n",
    "\n",
    "The running application has number of views to see what what data is moving through the stream. The following \n",
    "cell will fetch the views' queue and dipslay it's data when selected. \n",
    "\n",
    "|view name | description of data is the view |\n",
    "|---------|-------------|\n",
    "|allEvents  | all fields of all events  |\n",
    "|paredAll | subset of fields for all events |\n",
    "|paredHumans | subset of fields of all events where field 'bot is **False**|\n",
    "\n",
    "Running the cell below will bring up the list of active views from which data can be seen. \n",
    "\n",
    "When done 'Stop Updating', continious Widget updates are browser resource expensive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Render the views.....\n",
    "display_views(instance, job_name=\"WikiPhase1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing live data:\n",
    "- constructing the view object : https://streamsxtopology.readthedocs.io/en/latest/streamsx.topology.topology.html?highlight=view#streamsx.topology.topology.Stream.view\n",
    "- methods on the view object : https://streamsxtopology.readthedocs.io/en/latest/streamsx.topology.topology.html?highlight=view#streamsx.topology.topology.View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph frequency of 'type' events and 'bots'\n",
    "\n",
    "The following is a example of using widgets to view the live data, accessing the 'paredAll' view data, we're able to\n",
    "see the counts of edit types to bots/non-bot (human) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# tally the the bots/types\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "\n",
    "@catchInterrupt\n",
    "def tally_bot(view, ele_window=20, count=20):\n",
    "    \"\"\"bots vs human updates \n",
    "    Args:\n",
    "        view: Streams view that data will be fetched from\n",
    "        ele_window : max number of elements in window\n",
    "        count: number of times to fetch data, < 0 until interrupt \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    nam_list = ['new', 'edit', 'log','categorize']\n",
    "    cntbot = {key:0 for key in nam_list}\n",
    "    cntnobot = {key:0 for key in nam_list}\n",
    "    view.start_data_fetch()\n",
    "\n",
    "    while count != 0:\n",
    "        count -= 1\n",
    "        listTuples= view.fetch_tuples(max_tuples=20, timeout=4)\n",
    "        cntbot = Counter({key:0 for key in nam_list})\n",
    "        cntnobot = Counter({key:0 for key in nam_list})\n",
    "        for evt in listTuples:\n",
    "            if evt['bot']:\n",
    "                cntbot[evt['type']] += 1\n",
    "            else:\n",
    "                cntnobot[evt['type']] += 1\n",
    "        bot_list = [cntbot[key] for key in nam_list]\n",
    "        nobot_list = [cntnobot[key] for key in nam_list]\n",
    "        \n",
    "        df = pd.DataFrame({'bot': bot_list, ' nobot': nobot_list}, index=nam_list)\n",
    "        df.plot.bar(rot=0, stacked=True)\n",
    "        plt.ylim(0.0, ele_window)\n",
    "        plt.show()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "view = get_view(instance, job_name=\"WikiPhase1\", view_name=\"paredAll\")\n",
    "tally_bot(view=view[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph frequency of *bot*less 'type'  : Avg vs instant\n",
    "\n",
    "Display the last set of counts and the average of the last 20 sets utlizing the 'paredHuman' view. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate colllections of rows - support\n",
    "\n",
    "class chunking_average:\n",
    "    def __init__(self, init_base, mean_elements=20):\n",
    "        self.deques = {key:deque([0],maxlen=mean_elements) for key in init_base.keys()}\n",
    "\n",
    "    def aggregate(self, chunk):\n",
    "        for key in self.deques.keys():\n",
    "            if self.deques[key] and chunk[key]: self.deques[key].append(chunk[key])\n",
    "        return {key:mean(self.deques[key]) for key in self.deques.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "@catchInterrupt\n",
    "def tally_types(view, ele_window=20, count=20):\n",
    "    \"\"\"bar chart instant count vs running count. \n",
    "    Args:\n",
    "        view: Streams view that data will be fetched from\n",
    "        ele_window : max number of elements in window\n",
    "        count: number of times to fetch data, < 0 until interrupt \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    global resp\n",
    "    nam_list = ['new', 'edit', 'log','categorize']\n",
    "    cnt = {key:0 for key in nam_list}\n",
    "    run_avg = chunking_average(cnt)\n",
    "    view.start_data_fetch()\n",
    "\n",
    "\n",
    "    while count != 0:\n",
    "        count -= 1\n",
    "        listTuples= view.fetch_tuples(max_tuples=20, timeout=3)\n",
    "        cnt = Counter({key:0 for key in nam_list})\n",
    "        for evt in listTuples:cnt[evt['type']] += 1\n",
    "        avg = run_avg.aggregate(cnt)\n",
    "        evt_list = [cnt[key] for key in nam_list]\n",
    "        avg_list = [avg[key] for key in nam_list]\n",
    "        df = pd.DataFrame({'count': evt_list, 'running avg': avg_list}, index=nam_list)\n",
    "        df.plot.bar(rot=0)\n",
    "        plt.ylim(0.0, ele_window)\n",
    "        plt.show()\n",
    "        clear_output(wait=True)\n",
    "view = get_view(instance, job_name=\"WikiPhase1\", view_name=\"paredHuman\")\n",
    "tally_types(view=view[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancel job when done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "list_jobs(instance, cancel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook wrapup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook composed and deployed a Streams application that processes live Wikipedia events on a server. After \n",
    "filtering the events they're pared down and made avaiable via a view. Using standard notebook widgets\n",
    "we rendered the view data. \n",
    "\n",
    "This application is running on server, once deployed it is not necessary to have notebook open and executing in order to process the data. Future notebooks will collect and average data over windows of events and time. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
