{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmokeAvro \n",
    "Example of using Python, Avro and EventStreams to transport blob data. \n",
    "\n",
    "For convenience/compactness this is one application with two Streams, practically \n",
    "it would be 2 applications each with one Stream each.\n",
    "\n",
    "## needs\n",
    "Other than the streamsx components you'll need to sseclient.\n",
    "```\n",
    "  pip install sseclient\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sseclient import SSEClient as EventSource\n",
    "import streamsx\n",
    "from streamsx.topology.topology import *\n",
    "import streamsx.rest as rest\n",
    "from streamsx.topology import context\n",
    "from streamsx.eventstreams.schema import Schema\n",
    "import streamsx.eventstreams as eventstreams\n",
    "import streamsx.avro as avro\n",
    "\n",
    "## eventstreams credentials...\n",
    "import credential\n",
    "\n",
    "if '../scripts' not in sys.path:\n",
    "    sys.path.insert(0, '../scripts')\n",
    "import jupyter_streams\n",
    "#import cvsupport\n",
    "#import streams_operations\n",
    "#import streams_render\n",
    "\n",
    "\n",
    "## has credentials for cloud & kafka/event stream\n",
    "import logging\n",
    "print(\"topology\", streamsx.topology.topology.__version__)\n",
    "print(\"eventstreams\", eventstreams.__version__)\n",
    "print(\"avro\", avro.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance,cfg = jupyter_streams.get_instance(None, service_name='Streaming3Turbine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events():\n",
    "    \"\"\"fetch recent changes from wikievents site using SSE\n",
    "    \n",
    "    Notes::\n",
    "    Institutions keep their copy of wikipedia in order that it is not completly overwelme. \n",
    "    In order to keep these instances up to date, wikipedia reflect the changes make to the\n",
    "    site out on this SSE feed. \n",
    "        \n",
    "    \"\"\"\n",
    "    for change in EventSource('https://stream.wikimedia.org/v2/stream/recentchange'):\n",
    "        if len(change.data):\n",
    "            try:\n",
    "                obj = json.loads(change.data)\n",
    "            except json.JSONDecodeError as err:\n",
    "                print(\"JSON l1 error:\", err, \"Invalid JSON:\", change.data)\n",
    "            except json.decoder.JSONDecodeError as err:\n",
    "                print(\"JSON l2 error:\", err, \"Invalid JSON:\", change.data)\n",
    "            else:\n",
    "                yield(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AvroSndRcv application \n",
    "Example of using avro and Message hub to transmit data between Streams. \n",
    "\n",
    "- Serialize/deserialiation is done with Avro \n",
    "- Messages as transmitted in a binary format. \n",
    "- The schema is known to the reciever and transmitter.\n",
    "- Uses the SPL aggregate function to convert the blob schema to rectify this error : \"Blob schema is not currently supported for Python.\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamsx.avro as avro\n",
    "from streamsx.spl.toolkit import add_toolkit\n",
    "import streamsx.spl.op as op\n",
    "import streamsx.avro as avro\n",
    "from streamsx.eventstreams.schema import Schema\n",
    "from streamsx.eventstreams.schema import Schema as MsgSchema\n",
    "import streamsx.eventstreams.schema\n",
    "\n",
    "## Schema being transmitted via Avro.\n",
    "avro_schema=   '{\"type\" : \"record\",\"name\" :  \"wiki_schema\", \"fields\": [' \\\n",
    "'{\"name\":\"time_stamp\",\"type\": \"int\"},'  \\\n",
    "'{\"name\":\"id\",\"type\": \"string\"},'       \\\n",
    "'{\"name\":\"msg_type\",\"type\": \"string\"},' \\\n",
    "'{\"name\":\"wiki\",\"type\": \"string\"},'     \\\n",
    "'{\"name\":\"user\",\"type\": \"string\"}, '    \\\n",
    "'{\"name\":\"title\",\"type\": \"string\"}]}'\n",
    "\n",
    "\n",
    "def avro_sndrcv(jobName=None):\n",
    "    \"\"\"\n",
    "    Compose topology \n",
    "    \"\"\"\n",
    "    topo = Topology(name=jobName)\n",
    "    topo.add_pip_package('SSEClient===0.0.22')\n",
    "    avro_tk = avro.download_toolkit()\n",
    "    es_tk = eventstreams.download_toolkit()\n",
    "    add_toolkit(topo, avro_tk)\n",
    "    add_toolkit(topo, es_tk)\n",
    "\n",
    "\n",
    "    ## Get wiki data - This could be the start of applicagtion I\n",
    "    wiki_events = topo.source(get_events, name=\"wikiEvents\")\n",
    "    ## Filter out bots \n",
    "    all_human = wiki_events.filter(lambda x: x['bot'] is False, name='humanFilter')\n",
    "    ## pare down # of fields \n",
    "    pared_human = all_human.map(lambda x : {'time_stamp':x['timestamp'],'id':x['meta']['id'],'msg_type':x['type'],'wiki':x['wiki'],'user':x['user'],'title':x['title']}, name=\"paredAll\")\n",
    "    \n",
    "    avro_blob = avro.json_to_avro(pared_human.as_json(), avro_schema)\n",
    "\n",
    "    # Map to schema of eventstreams BinaryMessage\n",
    "    #  BinaryMessage : fields 'key', 'message'\n",
    "    avro_transmit = op.Map('spl.relational::Functor', avro_blob, \n",
    "                           schema = streamsx.eventstreams.schema.Schema.BinaryMessage)\n",
    "    avro_transmit.message = avro_transmit.output(avro_transmit.attribute('binary'))\n",
    "    avro_transmit.key = avro_transmit.output('\"key - necessary but inconsequential?\"')\n",
    "\n",
    "    eventstreams.publish(avro_transmit.stream, topic='TopicForward', \n",
    "                         credentials=json.loads(credential.magsEventStream))\n",
    "    # Receive wiki data - this could be the start of application II\n",
    "    from_kafka = eventstreams.subscribe(topo, topic='TopicForward', \n",
    "                                        schema= streamsx.eventstreams.schema.Schema.BinaryMessage, \n",
    "                                        credentials=json.loads(credential.magsEventStream))\n",
    "\n",
    "    ## Map from BinaryMessage's message -> avroMessage\n",
    "    avro_map =  op.Map('spl.relational::Functor', from_kafka, schema='tuple<blob arvoMessage>')\n",
    "    avro_map.arvoMessage = avro_map.output(avro_map.attribute('message'))\n",
    "    avro_map.stream.print(tag=\"mapped\", name=\"maped\")\n",
    "\n",
    "    ## arvoMessage will be de-serialized into avro_schema \n",
    "    avro_received = avro.avro_to_json(avro_map.stream, avro_schema)\n",
    "    avro_received.print(tag=\"avro_received\", name=\"avro_received\")\n",
    "    \n",
    "    ## separate the 'common' and 'french' wiki's out of the received eventstream\n",
    "    france = avro_received.filter(lambda x: x['name'] =='frwiki', name='franceFilter')\n",
    "    france.print(name=\"france\")\n",
    "\n",
    "    commons = avro_received.filter(lambda x: x['name'] =='commonswiki', name='commonsFilter')\n",
    "    commons.print(name=\"commons\")\n",
    "    \n",
    "   \n",
    "    return ({\"topo\":topo})\n",
    "\n",
    "topo = avro_sndrcv(\"AvroSndRcv\")[\"topo\"]\n",
    "jupyter_streams.commonSubmit(cfg, \"Streaming3Turbine\", topo, credential=credential)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_streams.list_jobs(instance, cancel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
